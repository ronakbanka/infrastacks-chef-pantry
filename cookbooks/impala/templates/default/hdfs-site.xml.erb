<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- about these variables: http://archive.cloudera.com/cdh/3/hadoop/hdfs-default.html -->
<!-- modified by chef, changes will be overwritten -->

<configuration>

<property>
    <name>dfs.client.read.shortcircuit</name>
    <value>true</value>
</property>

<property>
    <name>dfs.domain.socket.path</name>
    <value>/var/run/hadoop-hdfs/dn._PORT</value>
</property>

<property>
    <name>dfs.client.file-block-storage-locations.timeout</name>
    <value>3000</value>
</property>

<property> <name>dfs.secondary.http.address</name>       <value>0.0.0.0:<%= node[:hadoop][:secondarynn][:dash_port] %></value></property>
<property> <name>dfs.datanode.address</name>             <value>0.0.0.0:<%= node[:hadoop][:datanode][:xcvr_port]      %></value></property>
<property> <name>dfs.datanode.http.address</name>        <value>0.0.0.0:<%= node[:hadoop][:datanode][:dash_port] %></value></property>
<property> <name>dfs.datanode.ipc.address</name>         <value>0.0.0.0:<%= node[:hadoop][:datanode][:ipc_port]  %></value></property>

<property><name>dfs.name.dir</name>                      <value>file://<%= node[:hadoop][:namenode][:data_dirs].join(",") %></value><final>true</final></property>
<!-- <property><name>dfs.data.dir</name>                      <value><%= node[:hadoop][:datanode][:data_dirs].join(",") %></value><final>true</final></property> -->
<!-- <property><name>dfs.permissions</name>                   <value>true</value><final>true</final></property> -->

<!-- <property><name>dfs.block.size</name>                    <value><%= node[:hadoop][:hdfs_block_size] %></value></property> -->
<!-- <property><name>dfs.datanode.du.reserved</name>          <value>4073741824</value><final>true</final></property> -->
<!-- <property><name>dfs.replication</name>                   <value><%= node[:hadoop][:dfs_replication] %></value></property> -->

<!-- <property><name>dfs.datanode.handler.count</name>        <value><%= node[:hadoop][:datanode][:handler_count] %></value><final>true</final></property> -->
<!-- <property><name>dfs.namenode.handler.count</name>        <value><%= node[:hadoop][:namenode][:handler_count] %></value><final>true</final></property> -->
<!-- <property><name>dfs.datanode.max.xcievers</name>         <value>4096</value><final>true</final></property> -->
<!-- <property><name>dfs.datanode.max.xceivers</name>         <value>4096</value><final>true</final></property> -->
<!-- <property><name>dfs.datanode.socket.write.timeout</name> <value>0</value></property> -->
<!-- <property><name>dfs.balance.bandwidthPerSec</name>       <value><%= node[:hadoop][:balancer][:max_bandwidth] %></value></property> -->

<!-- <property><name>dfs.hosts.exclude</name>                 <value><%= node[:hadoop][:conf_dir] %>/dfs.hosts.exclude</value><final>true</final></property> -->

<!-- <property> <name>dfs.namenode.plugins</name> <value><%= node[:hadoop][:namenode][:plugins].join(",") %></value> <description>Comma-separated list of namenode plugins to be activated. </description> </property> -->
<!-- <property> <name>dfs.datanode.plugins</name> <value><%= node[:hadoop][:datanode][:plugins].join(",") %></value> <description>Comma-separated list of datanode plugins to be activated. </description> </property> -->
<!-- <property> <name>dfs.thrift.address</name> <value>0.0.0.0:<%= node[:hadoop][:thrift][:port] %></value> </property> -->

<!-- <property> <name>dfs.webhdfs.enabled</name> <value><%= node[:hadoop][:namenode][:webhdfs] %></value> </property> -->

<!-- <property><name>dfs.hosts</name>                    <value><%= node[:hadoop][:conf_dir] %>/dfs.hosts</value><final>true</final></property> -->

</configuration>
